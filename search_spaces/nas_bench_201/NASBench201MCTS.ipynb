{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import MCTS.mcts_agent\n",
    "import NASBench201MCTS\n",
    "importlib.reload(MCTS.mcts_agent)\n",
    "importlib.reload(NASBench201MCTS)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_theme(sns.plotting_context(\"notebook\", font_scale=1), style=\"whitegrid\", palette=sns.color_palette(\"deep\"))\n",
    "from MCTS.mcts_agent import MCTSAgent, UCT\n",
    "from NASBench201MCTS import NASBench201UCT, NASBench201RAVE, NASBench201GRAVE\n",
    "from nas_201_api import NASBench201API as API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "api = API('/userdata/T0259728/Bureau/NAS-Bench-201-v1_1-096897.pth', verbose=False)\n",
    "t2 = time.time()\n",
    "print(f\"API inistialized in {t2-t1} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NASBench201Node import NASBench201Node, NASBench201AMAFNode, NASBench201Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rewards_uct = []\n",
    "avg_best_reward_uct = []\n",
    "\n",
    "for n_run in range(N_RUNS):\n",
    "    print(f\"[{n_run}/{N_RUNS}]\")        \n",
    "    root_node = NASBench201Node(state=NASBench201Cell(4))\n",
    "    uct = NASBench201UCT(root_node, api,\n",
    "                      params_path=\"/userdata/T0259728/projets/nas/params.json\", disable_tqdm=True)\n",
    "    uct.C = 0.1\n",
    "    uct.n_iter=500\n",
    "    uct.playouts_per_selection = 1\n",
    "    returned_node, all_rewards, best_reward = uct.main_loop()\n",
    "    avg_rewards_uct.append(all_rewards)\n",
    "    avg_best_reward_uct.append(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rewards_rave = []\n",
    "avg_best_reward_rave = []\n",
    "\n",
    "for n_run in range(N_RUNS):\n",
    "    try: \n",
    "        print(f\"{n_run}/{N_RUNS}\")\n",
    "        root_node = NASBench201AMAFNode(state=NASBench201Cell(4))\n",
    "        rave = NASBench201RAVE(root_node, api,\n",
    "                          params_path=\"/userdata/T0259728/projets/nas/params.json\", disable_tqdm=True)\n",
    "        rave.C = 0.1\n",
    "        rave.b=0.1\n",
    "        rave.n_iter=500\n",
    "        rave.playouts_per_selection = 1\n",
    "        returned_node, all_rewards, best_reward = rave.main_loop()\n",
    "        avg_rewards_rave.append(all_rewards)\n",
    "        avg_best_reward_rave.append(best_reward)\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rewards_grave = []\n",
    "avg_best_reward_grave = []\n",
    "\n",
    "for n_run in range(N_RUNS):\n",
    "    try: \n",
    "        print(f\"{n_run}/{N_RUNS}\")\n",
    "        root_node = NASBench201AMAFNode(state=NASBench201Cell(4))\n",
    "        grave = NASBench201GRAVE(root_node, api,\n",
    "                          params_path=\"/userdata/T0259728/projets/nas/params.json\", disable_tqdm=True)\n",
    "        grave.C = 0.1\n",
    "        grave.b=0.1\n",
    "        grave.ref = 10\n",
    "        grave.n_iter=500\n",
    "        grave.playouts_per_selection = 1\n",
    "        returned_node, all_rewards, best_reward = grave.main_loop()\n",
    "        avg_rewards_grave.append(all_rewards)\n",
    "        avg_best_reward_grave.append(best_reward)\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.mean(np.array(avg_be st_reward_uct), axis=0), label=\"UCT\")\n",
    "plt.plot(np.mean(np.array(avg_best_reward_rave), axis=0), label=\"RAVE\")\n",
    "plt.plot(np.mean(np.array(avg_best_reward_grave), axis=0), label=\"GRAVE\")\n",
    "plt.title(\"Evolution of the best architecture reward \\n 400 iterations\"); plt.xlabel(\"Iteration\"); plt.ylabel(\"CIFAR-100 accuracy\"); plt.legend();\n",
    "plt.ylim([0.56,0.62]);\n",
    "# plt.savefig(\"../figures/uct_vs_rave_vs_grave_best_reward_400.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(MCTS.mcts_agent)\n",
    "importlib.reload(NASBench201MCTS)\n",
    "from NASBench201MCTS import NASBench201UCT_NTK\n",
    "import tensorly as tl\n",
    "tl.set_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rewards_uct_ntk = []\n",
    "avg_best_reward_uct_ntk = []\n",
    "avg_accuracies_uct_ntk = []\n",
    "avg_best_accuracy_uct_ntk = []\n",
    "\n",
    "for n_run in range(N_RUNS):\n",
    "    print(f\"[{n_run}/{N_RUNS}]\")        \n",
    "    root_node = NASBench201Node(state=NASBench201Cell(4))\n",
    "    ntk = NASBench201UCT_NTK(root_node, api,\n",
    "                      params_path=\"/userdata/T0259728/projets/nas/params.json\", disable_tqdm=False)\n",
    "    ntk.C = 0.1\n",
    "    ntk.n_iter=400\n",
    "    ntk.playouts_per_selection = 1\n",
    "    returned_node, all_rewards, best_reward, all_accuracies, best_accuracies = ntk.main_loop()\n",
    "    avg_rewards_uct_ntk.append(all_rewards)\n",
    "    avg_best_reward_uct_ntk.append(best_reward)\n",
    "    avg_accuracies_uct_ntk.append(all_accuracies)\n",
    "    avg_best_accuracy_uct_ntk.append(best_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(np.mean(np.array(avg_best_reward_uct), axis=0), label=\"UCT\")\n",
    "f, ax1 = plt.subplots()\n",
    "ax1.plot(np.mean(np.array(avg_best_reward_uct_ntk), axis=0), label=\"NTK Metric\", color=\"#3d405b\")\n",
    "ax1.set_ylabel(\"NTK Metric\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.mean(np.array(avg_best_accuracy_uct_ntk), axis=0), label=\"Accuracy\", color=\"#e07a5f\")\n",
    "ax2.set_ylabel(\"CIFAR-100 accuracy\")\n",
    "\n",
    "plt.title(\"Evolution of the best architecture reward \\n 400 iterations\"); plt.xlabel(\"Iteration\"); plt.ylabel(\"CIFAR-100 accuracy\"); \n",
    "plt.legend();\n",
    "# plt.ylim([0.56,0.62]);\n",
    "plt.savefig(\"../figures/ntk_metric.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(np.array(avg_best_reward_uct_ntk), axis=0), label=\"kzjnj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_best_reward_uct_ntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
